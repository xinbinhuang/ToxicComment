# Toxic Comment Classification
Create a model to predict the probabilities of each type toxicity.

- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate

## Data
[Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## Notebook
- [Exploratory notebook](./notebook/eda.ipynb)
- [Script to run the baseline model](./src/model.py)
